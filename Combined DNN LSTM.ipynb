{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as skl\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import random\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "from tensorflow.contrib.layers import dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_numpy(array):\n",
    "    \n",
    "    #if np.linalg.norm(list) == 0:\n",
    "    #    return list\n",
    "    #else:\n",
    "    normalized_array = stats.zscore(array)\n",
    "    return normalized_array\n",
    "\n",
    "with open('C:/Users/Robin Köster/Desktop/Studienarbeit ML/08_06_EINS/GANs/Energy_Data/2015_2017_hourly_DEATLU_load_PV_wind_forecast_noNA.csv', newline = '') as csvfile:\n",
    "    datareader = csv.reader(csvfile, delimiter = ';')\n",
    "    \n",
    "   # C:\\Users\\Robin Köster\\Desktop\\Studienarbeit ML\\Energy_data\n",
    "    \n",
    "    \n",
    "    data_array = np.array(list(datareader))    \n",
    "    \n",
    "date_np_array = np.array([np.array(data_array[i]) for i in range(1,len(data_array))])\n",
    "\n",
    "prices = np.array(list(map(lambda it: float(date_np_array[it,4]) , range(1,len(date_np_array))) ))\n",
    "\n",
    "prices_standardized = standardize_numpy(prices)\n",
    "\n",
    "load_forecast = standardize_numpy(np.array((\\\n",
    "                                        list(map(\\\n",
    "                                                 lambda it: float(date_np_array[it,1]) ,\\\n",
    "                                                 range(1,len(date_np_array))) ))) )\n",
    "\n",
    "wind_forecast = standardize_numpy(np.array((\\\n",
    "                                        list(map(\\\n",
    "                                                 lambda it: float(date_np_array[it,3]) , \\\n",
    "                                                 range(1,len(date_np_array))) ))) )\n",
    "\n",
    "pv_forecast = standardize_numpy(np.array(( \\\n",
    "                                      list(map( \\\n",
    "                                               lambda it: float(date_np_array[it,2]) , \\\n",
    "                                               range(1,len(date_np_array))) ))) )\n",
    "\n",
    "\n",
    "date_array = np.array(list(map(lambda it: datetime.strptime(date_np_array[it,0],'%d.%m.%Y %H:%M') , \\\n",
    "                               range(1,len(date_np_array))) ))\n",
    "\n",
    "day_of_week_array = standardize_numpy(np.array((\\\n",
    "                        list(map(lambda date: datetime.weekday(date), date_array)))) )\n",
    "\n",
    "hour_array = np.array(list(map(lambda date: datetime.time(date).hour, date_array)))\n",
    "\n",
    "# splitting the data into trainings set and validation set\n",
    "\n",
    "training_ratio = 0.8\n",
    "\n",
    "ind_split = np.round(training_ratio * len(prices)).astype(int)\n",
    "\n",
    "prices_training = prices[:ind_split]\n",
    "prices_validation = prices[ind_split:]\n",
    "\n",
    "prices_standardized_training = prices[:ind_split]\n",
    "prices_standardized_validation = prices[ind_split:]\n",
    "\n",
    "day_of_week_training = day_of_week_array[:ind_split]\n",
    "day_of_week_validation = day_of_week_array[ind_split:]\n",
    "\n",
    "hour_array_training = hour_array[:ind_split]\n",
    "hour_array_validation = hour_array[ind_split:]\n",
    "\n",
    "load_forecast_training = load_forecast[:ind_split]\n",
    "load_forecast_validation = load_forecast[ind_split:]\n",
    "\n",
    "wind_forecast_training = wind_forecast[:ind_split]\n",
    "wind_forecast_validation = wind_forecast[ind_split:]\n",
    "\n",
    "pv_forecast_training = pv_forecast[:ind_split]\n",
    "pv_forecast_validation = pv_forecast[ind_split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network architecture: \n",
    "# one LSTM network, which gets the prices of the previous day as input\n",
    "# one MLP, which gets just the day of the week as input\n",
    "\n",
    "# hyperparameters\n",
    "lrate = 1e-3\n",
    "mb_size = 50                  # size of mini batches\n",
    "time_series_past_length = 24  # number of hours in the \"conditional\" time series as input\n",
    "time_series_past_dim = 1      # number of featers included in the past time series\n",
    "conditions_length = 24\n",
    "conditions_dim = 4            # number of conditional inputs which should be processed by the MLP\n",
    "time_series_pred_length = 24  # number of hours in the predicted time series as output\n",
    "time_series_pred_dim = 1\n",
    "n_LSTM = 50                   # number of neurons in the LSTM layer (number of neurons in each \"step\" in the unrolled RNN)\n",
    "n_DNN = 100                      # number of neurons in the hidden layer of the DNN\n",
    "\n",
    "no_its = 100000\n",
    "\n",
    "def normalize_list_numpy(list):\n",
    "    \n",
    "    if np.linalg.norm(list) == 0:\n",
    "        prin(list)\n",
    "        return list\n",
    "    else:\n",
    "        normalized_list = list / np.linalg.norm(list)\n",
    "    return normalized_list\n",
    "\n",
    "def next_batch(size):\n",
    "    \n",
    "    ind_vec =  np.where(hour_array_training==0)[0]   # indices of data points with hour 0\n",
    "    ind_vec = list(ind_vec[:-2])                     # skip the last two elements\n",
    "    \n",
    "    random.seed( datetime.now() )\n",
    "    \n",
    "    ind_vec_shuffled = random.sample(ind_vec,len(ind_vec))\n",
    "\n",
    "    mb_ind = ind_vec_shuffled[0:(size)]\n",
    "    \n",
    "    mb_prices_day1 = np.array(list(map(lambda mb_first_ind: prices_training[mb_first_ind:(mb_first_ind+time_series_past_length)], mb_ind)))   \n",
    "    mb_prices_day2 = \\\n",
    "        np.array(list(map(lambda mb_first_ind: \\\n",
    "                           prices_training[(mb_first_ind+time_series_past_length):\\\n",
    "                                   (mb_first_ind+time_series_past_length+time_series_pred_length)], mb_ind)))\n",
    "    \n",
    "    # compute the weekday of the day, for which prices have to be predicted\n",
    "    weekday = \\\n",
    "        np.array((list(map(lambda mb_first_ind: \\\n",
    "                          day_of_week_training[mb_first_ind+time_series_past_length]*np.ones(1), \\\n",
    "                          mb_ind))))\n",
    "    \n",
    "    load_forecast = \\\n",
    "        np.array((list(map(lambda mb_first_ind: \\\n",
    "                           load_forecast_training[(mb_first_ind+time_series_past_length):\\\n",
    "                                   (mb_first_ind+time_series_past_length+time_series_pred_length)], mb_ind))))\n",
    "    \n",
    "    pv_forecast = \\\n",
    "        np.array((list(map(lambda mb_first_ind: \\\n",
    "                           pv_forecast_training[(mb_first_ind+time_series_past_length):\\\n",
    "                                   (mb_first_ind+time_series_past_length+time_series_pred_length)], mb_ind))))\n",
    "\n",
    "    wind_forecast = \\\n",
    "        np.array((list(map(lambda mb_first_ind: \\\n",
    "                           wind_forecast_training[(mb_first_ind+time_series_past_length):\\\n",
    "                                   (mb_first_ind+time_series_past_length+time_series_pred_length)], mb_ind))))\n",
    "    \n",
    "    #forecasts = np.concatenate((weekday, load_forecast, pv_forecast, wind_forecast), axis = 1)\n",
    "    #forecasts = np.concatenate((load_forecast, pv_forecast, wind_forecast), axis = 1)\n",
    "    forecasts = np.concatenate((load_forecast, wind_forecast, pv_forecast), axis = 1)    \n",
    "    return mb_prices_day1, mb_prices_day2, forecasts\n",
    "\n",
    "\n",
    "# input nodes for the time series of the previous day: x(t) as exogeneous variables\n",
    "past_input_nodes = tf.placeholder(tf.float32, shape=[None, time_series_past_length, time_series_past_dim])\n",
    "\n",
    "# input nodes for the conditional inputs for the day ahead\n",
    "future_input_nodes = tf.placeholder(tf.float32, shape=[None, conditions_length * (conditions_dim-1)])\n",
    "\n",
    "# nodes which the real prices may be assigned to during the training procedure\n",
    "real_prices_nodes = tf.placeholder(tf.float32, shape =[None, time_series_pred_length])\n",
    "\n",
    "# boolean whether its a training run and whether the dropout should be applied accordingly\n",
    "is_training = tf.placeholder(tf.bool, shape = (), name = 'is_training')\n",
    "\n",
    "\n",
    "##########   LSTM    #############################\n",
    "\n",
    "# create the LSTM cell\n",
    "lstm_cell = tf.contrib.rnn.OutputProjectionWrapper(\\\n",
    "                                tf.contrib.rnn.BasicLSTMCell \\\n",
    "                                (num_units = n_LSTM), output_size = 1)\n",
    "\n",
    "# include the cell in the graph\n",
    "lstm_output, lstm_states = tf.nn.dynamic_rnn(\\\n",
    "                            lstm_cell, past_input_nodes, dtype = tf.float32)\n",
    "\n",
    "##########    DNN    #############################\n",
    "\n",
    "DNN_h1 = tf.contrib.layers.fully_connected(future_input_nodes, n_DNN)\n",
    "\n",
    "lstm_output = tf.squeeze(lstm_output, axis =[2])\n",
    "########## MERGE  ################################\n",
    "\n",
    "merged_states = tf.concat((DNN_h1, lstm_output), axis = 1)\n",
    "\n",
    "output = tf.contrib.layers.fully_connected(merged_states, 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \tMSE: 846.6774\n",
      "1000 \tMSE: 19.150343\n",
      "2000 \tMSE: 58.818806\n",
      "3000 \tMSE: 24.865534\n",
      "4000 \tMSE: 7.538599\n",
      "5000 \tMSE: 6.6076694\n",
      "6000 \tMSE: 4.7036824\n",
      "7000 \tMSE: 4.535567\n",
      "8000 \tMSE: 2.1887705\n",
      "9000 \tMSE: 9.453052\n",
      "10000 \tMSE: 41.466442\n",
      "11000 \tMSE: 5.8194656\n",
      "12000 \tMSE: 12.427228\n",
      "13000 \tMSE: 20.28901\n",
      "14000 \tMSE: 4.2289615\n",
      "15000 \tMSE: 16.530798\n",
      "16000 \tMSE: 6.154017\n",
      "17000 \tMSE: 3.8965092\n",
      "18000 \tMSE: 4.002008\n",
      "19000 \tMSE: 9.605946\n",
      "20000 \tMSE: 15.894612\n",
      "21000 \tMSE: 5.0219793\n",
      "22000 \tMSE: 11.810532\n",
      "23000 \tMSE: 12.330302\n",
      "24000 \tMSE: 9.66838\n",
      "25000 \tMSE: 3.7147903\n",
      "26000 \tMSE: 30.74169\n",
      "27000 \tMSE: 1.9697766\n",
      "28000 \tMSE: 5.6441016\n",
      "29000 \tMSE: 8.595242\n",
      "30000 \tMSE: 14.800968\n",
      "31000 \tMSE: 3.8327048\n",
      "32000 \tMSE: 9.745759\n",
      "33000 \tMSE: 1.6422586\n",
      "34000 \tMSE: 4.1132913\n",
      "35000 \tMSE: 2.7953281\n",
      "36000 \tMSE: 6.058678\n",
      "37000 \tMSE: 4.95092\n",
      "38000 \tMSE: 10.361024\n",
      "39000 \tMSE: 10.334334\n",
      "40000 \tMSE: 13.760017\n",
      "41000 \tMSE: 12.598068\n",
      "42000 \tMSE: 22.513266\n",
      "43000 \tMSE: 2.8158529\n",
      "44000 \tMSE: 5.4200234\n",
      "45000 \tMSE: 9.417458\n",
      "46000 \tMSE: 60.64932\n",
      "47000 \tMSE: 2.7682269\n",
      "48000 \tMSE: 2.3915842\n",
      "49000 \tMSE: 2.6508834\n",
      "50000 \tMSE: 3.1746788\n",
      "51000 \tMSE: 7.421805\n",
      "52000 \tMSE: 7.431312\n",
      "53000 \tMSE: 14.503486\n",
      "54000 \tMSE: 2.5899255\n",
      "55000 \tMSE: 1.2472647\n",
      "56000 \tMSE: 5.2223363\n",
      "57000 \tMSE: 4.4875717\n",
      "58000 \tMSE: 5.0602593\n",
      "59000 \tMSE: 1.393001\n",
      "60000 \tMSE: 5.574268\n",
      "61000 \tMSE: 10.615217\n",
      "62000 \tMSE: 4.9309373\n",
      "63000 \tMSE: 2.2767568\n",
      "64000 \tMSE: 3.6488132\n",
      "65000 \tMSE: 2.8622296\n",
      "66000 \tMSE: 6.200664\n",
      "67000 \tMSE: 10.363112\n",
      "68000 \tMSE: 2.005173\n",
      "69000 \tMSE: 3.2949822\n",
      "70000 \tMSE: 2.9068725\n",
      "71000 \tMSE: 3.489022\n",
      "72000 \tMSE: 2.064539\n",
      "73000 \tMSE: 2.0781012\n",
      "74000 \tMSE: 2.5161862\n",
      "75000 \tMSE: 6.5181427\n",
      "76000 \tMSE: 2.4805753\n",
      "77000 \tMSE: 3.4851007\n",
      "78000 \tMSE: 2.3323638\n",
      "79000 \tMSE: 6.3581176\n",
      "80000 \tMSE: 2.728412\n",
      "81000 \tMSE: 5.1429467\n",
      "82000 \tMSE: 1.0909032\n",
      "83000 \tMSE: 0.98276407\n",
      "84000 \tMSE: 1.6375195\n",
      "85000 \tMSE: 4.5802975\n",
      "86000 \tMSE: 2.616245\n",
      "87000 \tMSE: 1.3708801\n",
      "88000 \tMSE: 3.6477947\n",
      "89000 \tMSE: 4.2058663\n",
      "90000 \tMSE: 1.2348839\n",
      "91000 \tMSE: 4.926275\n",
      "92000 \tMSE: 2.2922258\n",
      "93000 \tMSE: 5.184442\n",
      "94000 \tMSE: 8.779052\n",
      "95000 \tMSE: 3.969326\n",
      "96000 \tMSE: 2.3262618\n",
      "97000 \tMSE: 2.7029774\n",
      "98000 \tMSE: 5.786331\n",
      "99000 \tMSE: 3.707367\n"
     ]
    }
   ],
   "source": [
    "#### training of the model #######################\n",
    "\n",
    "import pylab\n",
    "\n",
    "loss = tf.reduce_mean(tf.square(output - real_prices_nodes))\n",
    "\n",
    "loss += reg_term\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = lrate)\n",
    "\n",
    "training_op = optimizer.minimize(loss)\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "if not os.path.exists('out/'):\n",
    "    os.makedirs('out/')\n",
    "    \n",
    "if not os.path.exists('cpkt_files/'):\n",
    "    os.makedirs('cpkt_files/')\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "i = 0\n",
    "\n",
    "for it in range(no_its):\n",
    "    X_mb_day1, X_mb_day2, forecasts = next_batch(mb_size)\n",
    "    \n",
    "    X_mb_day1_shaped = X_mb_day1[:,:,np.newaxis]\n",
    "    \n",
    "    sess.run(training_op, feed_dict = {past_input_nodes: X_mb_day1_shaped, \\\n",
    "                                       real_prices_nodes: X_mb_day2, \\\n",
    "                                       future_input_nodes: forecasts, \\\n",
    "                                       is_training: True})\n",
    "    \n",
    "    if it % 1000 == 0:\n",
    "        \n",
    "        X_mb_day1, X_mb_day2, forecasts = next_batch(1)\n",
    "    \n",
    "        X_mb_day1_shaped = X_mb_day1[:,:,np.newaxis]\n",
    "    \n",
    "        mse, prediction = sess.run([loss, output], \\\n",
    "                                   feed_dict = {past_input_nodes: X_mb_day1_shaped,\\\n",
    "                                                real_prices_nodes: X_mb_day2,\\\n",
    "                                                future_input_nodes: forecasts,\\\n",
    "                                                is_training: False})\n",
    "        print(it, \"\\tMSE:\", mse)\n",
    "        \n",
    "        \n",
    "        fig = plt.figure(figsize=(15,8))\n",
    "        fig = plt.plot(np.ndarray.flatten(X_mb_day2[0]), label='Real prices')\n",
    "        fig = plt.plot(np.ndarray.flatten(prediction[0]), label='Prediction')\n",
    "        pylab.legend(loc='upper left')\n",
    "\n",
    "        plt.savefig('out/{}.png'\n",
    "                    .format(str(i).zfill(4)), bbox_inches='tight')\n",
    "        i += 1\n",
    "        fig = plt.gcf()\n",
    "        plt.close(fig)\n",
    "    \n",
    "    if it % 5000 == 0:\n",
    "        save_path = saver.save(sess, \"cpkt_files/model.cpkt\")\n",
    "        \n",
    "save_path = saver.save(sess, \"cpkt_files/model_final.cpkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from cpkt_files/model_final.cpkt\n",
      "\n",
      " sMAPE:  7.775767826994347\n"
     ]
    }
   ],
   "source": [
    "# performance on training set\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    saver.restore(sess, \"cpkt_files/model_final.cpkt\")\n",
    "\n",
    "    \n",
    "    ind_vec =  np.where(hour_array_training==0)[0]   # indices of data points with hour 0\n",
    "    ind_vec = list(ind_vec[:-2])    # skip the last two weeks since they may be uncomplete\n",
    "    \n",
    "    \n",
    "    prices_day1 = np.array(list(map(lambda first_ind: \\\n",
    "                                           prices_training[first_ind:(first_ind+time_series_past_length)], ind_vec)))\n",
    "    \n",
    "    prices_day2 = \\\n",
    "        np.array(list(map(lambda first_ind: \\\n",
    "                           prices_training[(first_ind+time_series_past_length):\\\n",
    "                                   (first_ind+time_series_past_length+time_series_pred_length)], ind_vec)))\n",
    "    \n",
    "    pv_forecast = \\\n",
    "        np.array(list(map(lambda first_ind: \\\n",
    "                           pv_forecast_training[(first_ind+time_series_past_length):\\\n",
    "                                   (first_ind+time_series_past_length+time_series_pred_length)], ind_vec)))\n",
    "    wind_forecast = \\\n",
    "        np.array(list(map(lambda first_ind: \\\n",
    "                           wind_forecast_training[(first_ind+time_series_past_length):\\\n",
    "                                   (first_ind+time_series_past_length+time_series_pred_length)], ind_vec)))\n",
    "    load_forecast = \\\n",
    "        np.array(list(map(lambda first_ind: \\\n",
    "                           load_forecast_training[(first_ind+time_series_past_length):\\\n",
    "                                   (first_ind+time_series_past_length+time_series_pred_length)], ind_vec)))\n",
    "    \n",
    "    weekday = \\\n",
    "        np.array(list(map(lambda first_ind: \\\n",
    "                          day_of_week_training[first_ind+time_series_past_length] * np.ones(conditions_length), \\\n",
    "                          ind_vec)))\n",
    "    \n",
    "    forecasts = np.concatenate((load_forecast, wind_forecast, pv_forecast), axis = 1)\n",
    "    \n",
    "    forecasts = forecasts[:,np.newaxis]\n",
    "    \n",
    "    prices_day1 = prices_day1[:,np.newaxis,:, np.newaxis]\n",
    "    prices_day2 = prices_day2[:,np.newaxis,:]\n",
    "    \n",
    "    sMAPE = 0;\n",
    "    \n",
    "    for ind in range(prices_day1.shape[0]):\n",
    "        \n",
    "        predictions = sess.run([output], feed_dict = {past_input_nodes: prices_day1[ind], \\\n",
    "                                           real_prices_nodes: prices_day2[ind], \\\n",
    "                                           future_input_nodes: forecasts[ind], \\\n",
    "                                           is_training: False})\n",
    "        \n",
    "\n",
    "        predictions_array = np.array(predictions).flatten()\n",
    "        real_prices = prices_day2[ind].flatten()\n",
    "    \n",
    "        #print(np.intersect1d(np.where(predictions_array==0),np.where(real_prices==0)).size)\n",
    "\n",
    "        \n",
    "        if  np.intersect1d(np.where(predictions_array==0),np.where(real_prices==0)).size == 0:\n",
    "            sMAPE += 100 / (len(ind_vec) * len(real_prices)) * np.sum(\\\n",
    "                                 np.array(list(map(lambda y, y_hat: np.absolute(y-y_hat)*2/(np.absolute(y)+np.absolute(y_hat)), \\\n",
    "                                  real_prices, predictions_array ) )))\n",
    "        \n",
    "    print(\"\\n sMAPE: \",sMAPE)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from cpkt_files/model_final.cpkt\n",
      "\n",
      " sMAPE:  21.429276121074903\n"
     ]
    }
   ],
   "source": [
    "# performance on validation set\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    saver.restore(sess, \"cpkt_files/model_final.cpkt\")\n",
    "\n",
    "    \n",
    "    ind_vec =  np.where(hour_array_validation==0)[0]   # indices of data points with hour 0\n",
    "    ind_vec = list(ind_vec[:-2])    # skip the last two weeks since they may be uncomplete\n",
    "    \n",
    "    \n",
    "    prices_day1 = np.array(list(map(lambda first_ind: \\\n",
    "                                           prices_validation[first_ind:(first_ind+time_series_past_length)], ind_vec)))\n",
    "    \n",
    "    prices_day2 = \\\n",
    "        np.array(list(map(lambda first_ind: \\\n",
    "                           prices_validation[(first_ind+time_series_past_length):\\\n",
    "                                   (first_ind+time_series_past_length+time_series_pred_length)], ind_vec)))\n",
    "    \n",
    "    pv_forecast = \\\n",
    "        np.array(list(map(lambda first_ind: \\\n",
    "                           pv_forecast_validation[(first_ind+time_series_past_length):\\\n",
    "                                   (first_ind+time_series_past_length+time_series_pred_length)], ind_vec)))\n",
    "    wind_forecast = \\\n",
    "        np.array(list(map(lambda first_ind: \\\n",
    "                           wind_forecast_validation[(first_ind+time_series_past_length):\\\n",
    "                                   (first_ind+time_series_past_length+time_series_pred_length)], ind_vec)))\n",
    "    load_forecast = \\\n",
    "        np.array(list(map(lambda first_ind: \\\n",
    "                           load_forecast_validation[(first_ind+time_series_past_length):\\\n",
    "                                   (first_ind+time_series_past_length+time_series_pred_length)], ind_vec)))\n",
    "    \n",
    "    weekday = \\\n",
    "        np.array(list(map(lambda first_ind: \\\n",
    "                          day_of_week_validation[first_ind+time_series_past_length] * np.ones(conditions_length), \\\n",
    "                          ind_vec)))\n",
    "    \n",
    "    forecasts = np.concatenate((load_forecast, wind_forecast, pv_forecast), axis = 1)\n",
    "    \n",
    "    forecasts = forecasts[:,np.newaxis]\n",
    "    \n",
    "    prices_day1 = prices_day1[:,np.newaxis,:, np.newaxis]\n",
    "    prices_day2 = prices_day2[:,np.newaxis,:]\n",
    "    \n",
    "    sMAPE = 0;\n",
    "    \n",
    "    for ind in range(prices_day1.shape[0]):\n",
    "        \n",
    "        predictions = sess.run([output], feed_dict = {past_input_nodes: prices_day1[ind], \\\n",
    "                                           real_prices_nodes: prices_day2[ind], \\\n",
    "                                           future_input_nodes: forecasts[ind], \\\n",
    "                                           is_training: False})\n",
    "        \n",
    "\n",
    "        predictions_array = np.array(predictions).flatten()\n",
    "        real_prices = prices_day2[ind].flatten()\n",
    "    \n",
    "        #print(np.intersect1d(np.where(predictions_array==0),np.where(real_prices==0)).size)\n",
    "\n",
    "        \n",
    "        if  np.intersect1d(np.where(predictions_array==0),np.where(real_prices==0)).size == 0:\n",
    "            sMAPE += 100 / (len(ind_vec) * len(real_prices)) * np.sum(\\\n",
    "                                 np.array(list(map(lambda y, y_hat: np.absolute(y-y_hat)*2/(np.absolute(y)+np.absolute(y_hat)), \\\n",
    "                                  real_prices, predictions_array ) )))\n",
    "        \n",
    "    print(\"\\n sMAPE: \",sMAPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
